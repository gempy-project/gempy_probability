{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\nfrom pyvista import set_plot_theme\nset_plot_theme('document')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Intro to Bayesian Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport pyro\nimport pyro.distributions as dist\nfrom matplotlib.ticker import StrMethodFormatter\nfrom pyro.infer import MCMC, NUTS, Predictive\nimport arviz as az\nimport matplotlib.pyplot as plt\n\nfrom gempy_probability.plot_posterior import PlotPosterior\n\ny_obs = torch.tensor([2.12])\ny_obs_list = torch.tensor([2.12, 2.06, 2.08, 2.05, 2.08, 2.09,\n                           2.19, 2.07, 2.16, 2.11, 2.13, 1.92])\npyro.set_rng_seed(4003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def model(conf, data):\n    if conf in ['n_s', 'n_o']:\n        mu = pyro.sample('$\\mu$', dist.Normal(2.08, 0.07))\n    elif conf in ['u_s', 'u_o']:\n        mu = pyro.sample('$\\mu$', dist.Uniform(0, 10))\n    sigma = pyro.sample('$\\sigma$', dist.Gamma(0.3, 3))\n    y = pyro.sample('$y$', dist.Normal(mu, sigma), obs=data)\n    return y\n\n\ndef infer_model(config, data):\n    # 1. Prior Sampling\n    prior = Predictive(model, num_samples=100)(config, data)\n    # 2. MCMC Sampling\n    nuts_kernel = NUTS(model)\n    mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=100)  # Assuming 1000 warmup steps\n    mcmc.run(config, data)\n    # Get posterior samples\n    posterior_samples = mcmc.get_samples()\n    # 3. Sample from Posterior Predictive\n    posterior_predictive = Predictive(model, posterior_samples)(config, data)\n    # %%\n    az_data = az.from_pyro(\n        posterior=mcmc,\n        prior=prior,\n        posterior_predictive=posterior_predictive\n    )\n\n    return az_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The *data generating process* is latent. Therefore, it will be impossible to perfectly describe it. At this point,\nwe need to compromise and start to make assumptions and choose a model.\nAny probabilistic family, \\( \\pi(y;\\varTheta) \\), consists of two distinct sets: observations, \\( y \\) and model\nparameters \\( \\varTheta \\). Depending on which set is fixed, we obtain either (i) the forward view: for a given set \nof \\( \\varTheta \\) there is a probability of sample \\( y \\) or (ii) the inverse view: the observed \\( y \\) is so much \nlikely for these values of \\( \\varTheta \\). Discussing the nuances between assuming that the model emerge from \nobservations or if the observation are generated by the model are beyond the scope of this paper. Here, we stand on \nan eclectic position, arguing that these options are not mutually excluding, any (prior) model that the brain can \ncome up are substantiated\u2014in one way or another\u2014on direct observations of the present or in observations of the past \nconsolidated in form of experience. This reconciliation of statistical approaches it is formalised as Empirical Bayes. \nIn chapter XX, we will deepen on this topic while describing the proposed network for structural geology, for now, \nlet\u2019s assume that we perform inverse statistics and hence we fix the observations \\( y \\). For this example we can \nassume that the generating process belongs to the Gaussian family:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: Make the graph of the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "az_data = infer_model(\"u_s\", y_obs_list)\naz.plot_trace(az_data)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = PlotPosterior(az_data)\np.create_figure(figsize=(9, 3), joyplot=False, marginal=False)\np.plot_normal_likelihood('$\\mu$', '$\\sigma$', '$y$', iteration=-1, hide_bell=True)\np.likelihood_axes.set_xlim(1.90, 2.2)\np.likelihood_axes.xaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}'))\nfor tick in p.likelihood_axes.get_xticklabels():\n    tick.set_rotation(45)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No matter which probability density function we choose, for real applications we will never find the exact data \ngenerated process---neither we will be able to say if we have found it for that matter---due to an oversimplification \nof reality. For most applications, the usual families of probability density functions and transformations of those \nare more than enough approximations for the purpose of the model. In Chapter [sec:model_selection], we will delve into \nthis topic.\n\nOnce the model is defined we need to infer the set of parameters \\( \\varTheta \\) of the family of density functions \nover the observational space, \\( \\pi_S(y;\\varTheta) \\). In the case of the normal family, we need to infer the value \nof the mean, \\( \\mu \\) and standard deviation \\( \\sigma \\). Up to this point, all the description of the probabilistic \nmodelling is agnostic in relation to Frequentist or Bayesian views. These two methodologies diverge on how they \ninfer \\( \\varTheta \\).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = PlotPosterior(az_data)\np.create_figure(figsize=(9, 3), joyplot=False, marginal=False)\np.plot_normal_likelihood('$\\mu$', '$\\sigma$', '$y$', iteration=-1, hide_lines=True)\np.likelihood_axes.set_xlim(1.70, 2.40)\np.likelihood_axes.xaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}'))\nfor tick in p.likelihood_axes.get_xticklabels():\n    tick.set_rotation(45)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = PlotPosterior(az_data)\n\np.create_figure(figsize=(9, 9), joyplot=True, marginal=False, likelihood=False, n_samples=31)\np.plot_joy(('$\\mu$', '$\\sigma$'), '$y$', iteration=14)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = PlotPosterior(az_data)\n\np.create_figure(figsize=(9, 5), joyplot=False, marginal=True, likelihood=True)\np.plot_marginal(var_names=['$\\mu$', '$\\sigma$'],\n                plot_trace=False, credible_interval=.93, kind='kde',\n                joint_kwargs={'contour': True, 'pcolormesh_kwargs': {}},\n                joint_kwargs_prior={'contour': False, 'pcolormesh_kwargs': {}})\n\np.plot_normal_likelihood('$\\mu$', '$\\sigma$', '$y$', iteration=-1, hide_lines=True)\np.likelihood_axes.set_xlim(1.70, 2.40)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "az_data = infer_model(\"u_o\", y_obs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = PlotPosterior(az_data)\n\np.create_figure(figsize=(9, 5), joyplot=False, marginal=True, likelihood=True)\np.plot_marginal(var_names=['$\\mu$', '$\\sigma$'],\n                plot_trace=False, credible_interval=.93, kind='kde',\n                joint_kwargs={'contour': True, 'pcolormesh_kwargs': {}},\n                joint_kwargs_prior={'contour': False, 'pcolormesh_kwargs': {}})\n\np.axjoin.set_xlim(1.96, 2.22)\np.plot_normal_likelihood('$\\mu$', '$\\sigma$', '$y$', iteration=-6, hide_lines=True)\np.likelihood_axes.set_xlim(1.70, 2.40)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "az_data = infer_model(\"u_s\", y_obs_list)\np = PlotPosterior(az_data)\n\np.create_figure(figsize=(9, 5), joyplot=False, marginal=True, likelihood=True)\np.plot_marginal(var_names=['$\\mu$', '$\\sigma$'],\n                plot_trace=False, credible_interval=.93, kind='kde',\n                joint_kwargs={'contour': True, 'pcolormesh_kwargs': {}},\n                joint_kwargs_prior={'contour': False, 'pcolormesh_kwargs': {}})\n\np.plot_normal_likelihood('$\\mu$', '$\\sigma$', '$y$', iteration=-5, hide_lines=True)\np.axjoin.set_xlim(1.96, 2.22)\np.likelihood_axes.set_xlim(1.70, 2.4)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# License\nThe code in this case study is copyrighted by Miguel de la Varga and licensed under the new BSD (3-clause) license:\n\nhttps://opensource.org/licenses/BSD-3-Clause\n\nThe text and figures in this case study are copyrighted by Miguel de la Varga and licensed under the CC BY-NC 4.0 license:\n\nhttps://creativecommons.org/licenses/by-nc/4.0/\nMake sure to replace the links with actual hyperlinks if you're using a platform that supports it (e.g., Markdown or HTML). Otherwise, the plain URLs work fine for plain text.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}