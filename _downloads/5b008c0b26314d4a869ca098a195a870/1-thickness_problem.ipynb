{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\nfrom pyvista import set_plot_theme\nset_plot_theme('document')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 2.1 - Only Pyro\n\n\n## Model definition\n\nSame problem as before, let\u2019s assume the observations are layer\nthickness measurements taken on an outcrop. Now, in the previous example\nwe chose a prior for the mean arbitrarily:\n$\ud835\udf07\u223cNormal(mu=10.0, sigma=5.0)$\u2013something that made sense for these\nspecific data set. If we do not have any further information, keeping\nan uninformative prior and let the data to dictate the final value of\nthe inference is the sensible way forward. However, this also enable to\nadd information to the system by setting informative priors.\n\nImagine we get a borehole with the tops of the two interfaces of\ninterest. Each of this data point will be a random variable itself since\nthe accuracy of the exact 3D location will be always limited. Notice\nthat this two data points refer to depth not to thickness\u2013the unit of\nthe rest of the observations. Therefore, the first step would be to\nperform a transformation of the parameters into the observations space.\nNaturally in this example a simple subtraction will suffice.\n\nNow we can define the probabilistic models:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = -2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Necessary Libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport io\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport pyro\nimport pyro.distributions as dist\nimport torch\nfrom pyro.infer import MCMC, NUTS, Predictive\nfrom pyro.infer.inspect import get_dependencies\nfrom gempy_probability.plot_posterior import PlotPosterior, default_red, default_blue\nimport arviz as az\n\naz.style.use(\"arviz-doc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to the Problem\nIn this example, we are considering layer thickness measurements taken on an outcrop as our observations.\nWe use a probabilistic approach to model these observations, allowing for the inclusion of prior knowledge\nand uncertainty quantification.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Setting the working directory for sphinx gallery\ncwd = os.getcwd()\nif 'examples' not in cwd:\n    path_dir = os.getcwd() + '/examples/tutorials/ch5_probabilistic_modeling'\nelse:\n    path_dir = cwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the Observations and Model\nThe observations are layer thickness measurements. We define a Pyro probabilistic model\nthat uses Normal and Gamma distributions to model the top and bottom interfaces of the layers\nand their respective uncertainties.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Defining observed data\ny_obs = torch.tensor([2.12])\ny_obs_list = torch.tensor([2.12, 2.06, 2.08, 2.05, 2.08, 2.09, 2.19, 2.07, 2.16, 2.11, 2.13, 1.92])\npyro.set_rng_seed(4003)\n\n\n# Defining the probabilistic model\ndef model(y_obs_list_):\n    mu_top = pyro.sample(r'$\\mu_{top}$', dist.Normal(3.05, 0.2))\n    sigma_top = pyro.sample(r\"$\\sigma_{top}$\", dist.Gamma(0.3, 3.0))\n    y_top = pyro.sample(r\"y_{top}\", dist.Normal(mu_top, sigma_top), obs=torch.tensor([3.02]))\n\n    mu_bottom = pyro.sample(r'$\\mu_{bottom}$', dist.Normal(1.02, 0.2))\n    sigma_bottom = pyro.sample(r'$\\sigma_{bottom}$', dist.Gamma(0.3, 3.0))\n    y_bottom = pyro.sample(r'y_{bottom}', dist.Normal(mu_bottom, sigma_bottom), obs=torch.tensor([1.02]))\n\n    mu_thickness = pyro.deterministic(r'$\\mu_{thickness}$', mu_top - mu_bottom)\n    sigma_thickness = pyro.sample(r'$\\sigma_{thickness}$', dist.Gamma(0.3, 3.0))\n    y_thickness = pyro.sample(r'y_{thickness}', dist.Normal(mu_thickness, sigma_thickness), obs=y_obs_list_)\n\n\n# Exploring model dependencies\ndependencies = get_dependencies(model, model_args=y_obs_list[:1])\ndependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = pyro.render_model(\n    model=model,\n    model_args=(y_obs_list,),\n    render_params=True,\n    render_distributions=True,\n    render_deterministic=True\n)\n\ngraph.attr(dpi='300')\n# Convert the graph to a PNG image format\ns = graph.pipe(format='png')\n\n# Open the image with PIL\nimage = Image.open(io.BytesIO(s))\n\n# Plot the image with matplotlib\nplt.figure(figsize=(10, 4))\nplt.imshow(image)\nplt.axis('off')  # Turn off axis\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prior Sampling\nPrior sampling is performed to understand the initial distribution of the model parameters\nbefore considering the observed data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Prior sampling\nnum_samples= 500\nprior = Predictive(model, num_samples=num_samples)(y_obs_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running MCMC Sampling\nMarkov Chain Monte Carlo (MCMC) sampling is used to sample from the posterior distribution,\nproviding insights into the distribution of model parameters after considering the observed data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Running MCMC using the NUTS algorithm\nnuts_kernel = NUTS(model)\nmcmc = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=100)\nmcmc.run(y_obs_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Posterior Predictive Sampling\nAfter obtaining the posterior samples, we perform posterior predictive sampling.\nThis step allows us to make predictions based on the posterior distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Sampling from the posterior predictive distribution\nposterior_samples = mcmc.get_samples(num_samples)\nposterior_predictive = Predictive(model, posterior_samples)(y_obs_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the Results\nWe use ArviZ, a library for exploratory analysis of Bayesian models, to visualize\nthe results of our probabilistic model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Creating a data object for ArviZ\ndata = az.from_pyro(\n    posterior=mcmc,\n    prior=prior,\n    posterior_predictive=posterior_predictive\n)\n\n# Plotting trace of the sampled parameters\naz.plot_trace(data, kind=\"trace\", figsize=(10, 10), compact=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting trace of the sampled parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "az.plot_trace(posterior_predictive, var_names= (r\"$\\mu_{thickness}$\"), kind=\"trace\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Density Plots of Posterior and Prior\nDensity plots provide a visual representation of the distribution of the sampled parameters.\nComparing the posterior and prior distributions allows us to assess the impact of the observed data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plotting density of posterior and prior distributions\naz.plot_density(\n    data=[data, data.prior],\n    hdi_prob=0.95,\n    shade=.2,\n    data_labels=[\"Posterior\", \"Prior\"],\n    colors=[default_red, default_blue],\n)\n\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can we see a correlation between the posteriors of $\\mu_{bottom}$ and $\\mu_{top}$?\n\n## Density Plots of Posterior Predictive and Prior Predictive\nThese plots show the distribution of the posterior predictive and prior predictive checks.\nThey help in evaluating the performance and validity of the probabilistic model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plotting density of posterior predictive and prior predictive\naz.plot_density(\n    data=[data.posterior_predictive, data.prior_predictive],\n    shade=.2,\n    var_names=[r'$\\mu_{thickness}$'],\n    data_labels=[\"Posterior Predictive\", \"Prior Predictive\"],\n    colors=[default_red, default_blue],\n    hdi_prob=0.90\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Marginal Distribution Plots\nMarginal distribution plots provide insights into the distribution of individual parameters.\nThese plots help in understanding the uncertainty and variability in the parameter estimates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Creating marginal distribution plots\np = PlotPosterior(data)\np.create_figure(figsize=(9, 5), joyplot=False, marginal=True, likelihood=False)\np.plot_marginal(\n    var_names=['$\\\\mu_{top}$', '$\\\\mu_{bottom}$'],\n    plot_trace=False,\n    credible_interval=1,\n    kind='kde',\n    marginal_kwargs={\n            \"bw\": \"scott\"\n    },\n    joint_kwargs={\n            'contour'          : True,\n            'pcolormesh_kwargs': {}\n    },\n    joint_kwargs_prior={\n            'contour'          : False,\n            'pcolormesh_kwargs': {}\n    }\n\n)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Posterior Distribution Visualization\nThis section provides a more detailed visualization of the posterior distributions\nof the parameters, integrating different aspects of the probabilistic model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Visualizing the posterior distributions\np = PlotPosterior(data)\np.create_figure(figsize=(9, 6), joyplot=True)\niteration = 450\np.plot_posterior(\n    prior_var=['$\\\\mu_{top}$', '$\\\\mu_{bottom}$'],\n    like_var=['$\\\\mu_{top}$', '$\\\\mu_{bottom}$'],\n    obs='y_{thickness}',\n    iteration=iteration,\n    marginal_kwargs={\n            \"credible_interval\" : .9999,\n            'marginal_kwargs'   : {},\n            'joint_kwargs'      : {\n                    \"bw\"               : 1,\n                    'contour'          : True,\n                    'pcolormesh_kwargs': {}\n            },\n            \"joint_kwargs_prior\": {\n                    'contour'          : False,\n                    'pcolormesh_kwargs': {}\n            }\n    })\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pair Plot of Key Parameters\nPair plots are useful to visualize the relationships and correlations between different parameters.\nThey help in understanding how parameters influence each other in the probabilistic model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Creating a pair plot for selected parameters\naz.plot_pair(data, divergences=False, var_names=['$\\\\mu_{top}$', '$\\\\mu_{bottom}$'])\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}