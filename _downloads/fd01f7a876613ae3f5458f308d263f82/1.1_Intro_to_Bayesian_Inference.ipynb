{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\nfrom pyvista import set_plot_theme\nset_plot_theme('document')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Normal Prior, single observation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = -1\n\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pyro\nimport torch\n\nfrom gempy_probability.plot_posterior import PlotPosterior\nfrom _aux_func import infer_model\n\naz.style.use(\"arviz-doc\")\n\ny_obs = torch.tensor([2.12])\ny_obs_list = torch.tensor([2.12, 2.06, 2.08, 2.05, 2.08, 2.09,\n                           2.19, 2.07, 2.16, 2.11, 2.13, 1.92])\npyro.set_rng_seed(4003)\n\n# Before diving in sampling, let's look at a model, where we have a single observation to sample the posterior from a prior with a normal\n# distribution for :math:`\\mu` and a gamma distribution for :math:`\\sigma`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "az_data = infer_model(\n    distributions_family=\"normal_distribution\",\n    data=y_obs\n)\naz.plot_trace(az_data)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prior Space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = PlotPosterior(az_data)\n\np.create_figure(figsize=(9, 5), joyplot=False, marginal=True, likelihood=True)\np.plot_marginal(\n    var_names=['$\\\\mu_{likelihood}$', '$\\\\sigma_{likelihood}$'],\n    plot_trace=False,\n    credible_interval=.93,\n    kind='kde',\n    group=\"prior\",\n    joint_kwargs={\n            'contour'          : True,\n            'pcolormesh_kwargs': {}\n    },\n    joint_kwargs_prior={\n            'contour': False,\n            'pcolormesh_kwargs': {}\n    }\n)\n\np.axjoin.set_xlim(1.96, 2.22)\np.plot_normal_likelihood(\n    mean='$\\\\mu_{likelihood}$',\n    std='$\\\\sigma_{likelihood}$',\n    obs='$y$',\n    iteration=-6,\n    hide_lines=True\n)\np.likelihood_axes.set_xlim(1.70, 2.40)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prior and Posterior Space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_posterior(iteration=-1):\n    p = PlotPosterior(az_data)\n\n    p.create_figure(figsize=(9, 5), joyplot=False, marginal=True, likelihood=True)\n    p.plot_marginal(\n        var_names=['$\\\\mu_{likelihood}$', '$\\\\sigma_{likelihood}$'],\n        plot_trace=True,\n        credible_interval=.93,\n        iteration=iteration,\n        kind='kde',\n        group=\"both\",\n        joint_kwargs={\n                'contour'          : True,\n                'pcolormesh_kwargs': {}\n        },\n        joint_kwargs_prior={\n                'contour'          : False,\n                'pcolormesh_kwargs': {}\n        }\n    )\n\n    p.axjoin.set_xlim(1.96, 2.22)\n    p.plot_normal_likelihood(\n        mean='$\\\\mu_{likelihood}$',\n        std='$\\\\sigma_{likelihood}$',\n        obs='$y$',\n        iteration=iteration,\n        hide_lines=False\n    )\n    p.likelihood_axes.set_xlim(1.96, 2.22)\n    p.fig.set_label(f'Iteration {iteration}')\n    plt.show()\n\n\nfor i in np.linspace(50, 800, 5, dtype=int):\n    plot_posterior(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MCMC boils down to be a collection of methods helping to do Bayesian inference, thus based on Bayes Theorem:\n\n\\begin{align}P(\\theta | x) = \\frac{P(x|\\theta) P(\\theta)}{P(x)}\\end{align}\n\n* $P(\\theta | x)$ is the Posterior\n* $P(x)$ is the Prior\n* $P(x | \\theta)$ is the Likelihood\n* $P(x)$ is the Evidence\n\nAs calculating the posterior in this form is most likely not possible in real-world problems, if one could sample from the posterior,\none might approximate it with Monte Carlo. But in order to sample directly from the posterior, one would need to invert Bayes Theorem.\n\nThe solution to this problem is, when we cannot draw Monte Carlo (MC) samples from the distribution directly, we let a Markov Chain\ndo it for us. [1]\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What con we do next? \nIncreasing the number of observations - sampling (:doc:`1.2_Intro_to_Bayesian_Inference`)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# License\nThe code in this case study is copyrighted by Miguel de la Varga and licensed under the new BSD (3-clause) license:\n\nhttps://opensource.org/licenses/BSD-3-Clause\n\nThe text and figures in this case study are copyrighted by Miguel de la Varga and licensed under the CC BY-NC 4.0 license:\n\nhttps://creativecommons.org/licenses/by-nc/4.0/\nMake sure to replace the links with actual hyperlinks if you're using a platform that supports it (e.g., Markdown or HTML). Otherwise, the plain URLs work fine for plain text.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}