# TODO:

--- General
- [ ] Create a proper suit of tests
  - [ ] Keep extracting code into modules and functions 
  - [ ] Posterior analysis for gempy 
- [ ] Investigate speed
- [ ] Investigate segmentation function
  https://chatgpt.com/share/68172f53-4f7c-8000-8f42-205a033ed899
- [ ] Create a robust api to make sure we do not mess up assigning priors to gempy parameters
- [ ] do we need to use index_put or just normal indexing?
--- Vector examples
- [ ] Bring the Vector example here...
- [ ] Using categories as likelihood function (maybe I need to check out with Sam)
--- MinEye
- [ ] Revive magnetics
- [ ] Add Simon's example

### Doing:
- [x] Compressing code
- [x] GemPy posterior visualization
- [x] Add proper thickness likelihood
- [ ] Speed
  - [ ] Time test for torch CPU
  - [ ] Time test for keops CPU
  - [ ] Time test for keops GPU
  - [ ] Options and config presets
   
### Possible Design:
- Geological Model
- Priors
- Likelihood
----
- Having a runner or something like that?

### Saving posteriors gempy models for later analysis
- ? Do we want to try to save the full input as versioning so that we can just have one system to go back and forth?

### Likelihood functions
- ? Should I start to create a catalog of likelihood functions that goes with gempy?
  - This would be useful to be able to visualize whatever the likelihood function represents independent of the probabilistic model.