<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Intro to Bayesian Inference &#8212; GemPy 2023.2.0b1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=270d38c7" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=e5fbc548" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=39c4bfd0"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-examples-first-example-of-inference-1-bayesian-basics-1-intro-to-bayesian-inference-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="intro-to-bayesian-inference">
<span id="sphx-glr-examples-first-example-of-inference-1-bayesian-basics-1-intro-to-bayesian-inference-py"></span><h1>Intro to Bayesian Inference<a class="headerlink" href="#intro-to-bayesian-inference" title="Permalink to this heading">¶</a></h1>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">StrMethodFormatter</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="kn">import</span> <span class="n">MCMC</span><span class="p">,</span> <span class="n">NUTS</span><span class="p">,</span> <span class="n">Predictive</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">gempy_probability.plot_posterior</span> <span class="kn">import</span> <span class="n">PlotPosterior</span>

<span class="n">y_obs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.12</span><span class="p">])</span>
<span class="n">y_obs_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.12</span><span class="p">,</span> <span class="mf">2.06</span><span class="p">,</span> <span class="mf">2.08</span><span class="p">,</span> <span class="mf">2.05</span><span class="p">,</span> <span class="mf">2.08</span><span class="p">,</span> <span class="mf">2.09</span><span class="p">,</span>
                           <span class="mf">2.19</span><span class="p">,</span> <span class="mf">2.07</span><span class="p">,</span> <span class="mf">2.16</span><span class="p">,</span> <span class="mf">2.11</span><span class="p">,</span> <span class="mf">2.13</span><span class="p">,</span> <span class="mf">1.92</span><span class="p">])</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="mi">4003</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">conf</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;n_s&#39;</span><span class="p">,</span> <span class="s1">&#39;n_o&#39;</span><span class="p">]:</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">2.08</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">conf</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;u_s&#39;</span><span class="p">,</span> <span class="s1">&#39;u_o&#39;</span><span class="p">]:</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;$\sigma$&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="k">def</span> <span class="nf">infer_model</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="c1"># 1. Prior Sampling</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)(</span><span class="n">config</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="c1"># 2. MCMC Sampling</span>
    <span class="n">nuts_kernel</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">mcmc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">nuts_kernel</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># Assuming 1000 warmup steps</span>
    <span class="n">mcmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="c1"># Get posterior samples</span>
    <span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">mcmc</span><span class="o">.</span><span class="n">get_samples</span><span class="p">()</span>
    <span class="c1"># 3. Sample from Posterior Predictive</span>
    <span class="n">posterior_predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">posterior_samples</span><span class="p">)(</span><span class="n">config</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="c1"># %%</span>
    <span class="n">az_data</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_pyro</span><span class="p">(</span>
        <span class="n">posterior</span><span class="o">=</span><span class="n">mcmc</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">posterior_predictive</span><span class="o">=</span><span class="n">posterior_predictive</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">az_data</span>
</pre></div>
</div>
<p>The <em>data generating process</em> is latent. Therefore, it will be impossible to perfectly describe it. At this point,
we need to compromise and start to make assumptions and choose a model.
Any probabilistic family, ( pi(y;varTheta) ), consists of two distinct sets: observations, ( y ) and model
parameters ( varTheta ). Depending on which set is fixed, we obtain either (i) the forward view: for a given set
of ( varTheta ) there is a probability of sample ( y ) or (ii) the inverse view: the observed ( y ) is so much
likely for these values of ( varTheta ). Discussing the nuances between assuming that the model emerge from
observations or if the observation are generated by the model are beyond the scope of this paper. Here, we stand on
an eclectic position, arguing that these options are not mutually excluding, any (prior) model that the brain can
come up are substantiated—in one way or another—on direct observations of the present or in observations of the past
consolidated in form of experience. This reconciliation of statistical approaches it is formalised as Empirical Bayes.
In chapter XX, we will deepen on this topic while describing the proposed network for structural geology, for now,
let’s assume that we perform inverse statistics and hence we fix the observations ( y ). For this example we can
assume that the generating process belongs to the Gaussian family:</p>
<p>TODO: Make the graph of the model</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">az_data</span> <span class="o">=</span> <span class="n">infer_model</span><span class="p">(</span><span class="s2">&quot;u_s&quot;</span><span class="p">,</span> <span class="n">y_obs_list</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">az_data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_001.png" srcset="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_001.png" alt="$\mu$, $\mu$, $\sigma$, $\sigma$" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Warmup:   0%|          | 0/200 [00:00, ?it/s]
Warmup:  10%|#         | 20/200 [00:00, 161.70it/s, step size=1.11e-02, acc. prob=0.709]
Warmup:  18%|#8        | 37/200 [00:00, 160.16it/s, step size=3.82e-02, acc. prob=0.756]
Warmup:  27%|##7       | 54/200 [00:00, 123.54it/s, step size=1.87e-02, acc. prob=0.761]
Warmup:  36%|###5      | 71/200 [00:00, 134.39it/s, step size=2.83e-02, acc. prob=0.770]
Warmup:  43%|####3     | 86/200 [00:00, 120.49it/s, step size=8.86e-03, acc. prob=0.766]
Sample:  54%|#####4    | 108/200 [00:00, 147.57it/s, step size=5.24e-01, acc. prob=0.949]
Sample:  72%|#######2  | 144/200 [00:00, 206.54it/s, step size=5.24e-01, acc. prob=0.935]
Sample:  89%|########9 | 178/200 [00:00, 244.34it/s, step size=5.24e-01, acc. prob=0.944]
Sample: 100%|##########| 200/200 [00:01, 194.11it/s, step size=5.24e-01, acc. prob=0.944]

/home/leguark/.virtualenvs/gempy-geotop-pilot/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: gempy.-version- is an invalid version and will not be supported in a future release
  warnings.warn(
/home/leguark/.virtualenvs/gempy-geotop-pilot/lib/python3.10/site-packages/arviz/data/io_pyro.py:157: UserWarning: Could not get vectorized trace, log_likelihood group will be omitted. Check your model vectorization or set log_likelihood=False
  warnings.warn(
</pre></div>
</div>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">PlotPosterior</span><span class="p">(</span><span class="n">az_data</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">create_figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">joyplot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">marginal</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">plot_normal_likelihood</span><span class="p">(</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">,</span> <span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">hide_bell</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">1.90</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">StrMethodFormatter</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{x:,.2f}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">tick</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">():</span>
    <span class="n">tick</span><span class="o">.</span><span class="n">set_rotation</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_002.png" srcset="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_002.png" alt="Likelihood" class = "sphx-glr-single-img"/><p>No matter which probability density function we choose, for real applications we will never find the exact data
generated process—neither we will be able to say if we have found it for that matter—due to an oversimplification
of reality. For most applications, the usual families of probability density functions and transformations of those
are more than enough approximations for the purpose of the model. In Chapter [sec:model_selection], we will delve into
this topic.</p>
<p>Once the model is defined we need to infer the set of parameters ( varTheta ) of the family of density functions
over the observational space, ( pi_S(y;varTheta) ). In the case of the normal family, we need to infer the value
of the mean, ( mu ) and standard deviation ( sigma ). Up to this point, all the description of the probabilistic
modelling is agnostic in relation to Frequentist or Bayesian views. These two methodologies diverge on how they
infer ( varTheta ).</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">PlotPosterior</span><span class="p">(</span><span class="n">az_data</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">create_figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">joyplot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">marginal</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">plot_normal_likelihood</span><span class="p">(</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">,</span> <span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">hide_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">1.70</span><span class="p">,</span> <span class="mf">2.40</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">StrMethodFormatter</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{x:,.2f}</span><span class="s1">&#39;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">tick</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">():</span>
    <span class="n">tick</span><span class="o">.</span><span class="n">set_rotation</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_003.png" srcset="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_003.png" alt="Likelihood" class = "sphx-glr-single-img"/><div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">PlotPosterior</span><span class="p">(</span><span class="n">az_data</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">create_figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">joyplot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">marginal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">31</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">plot_joy</span><span class="p">((</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">),</span> <span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_004.png" srcset="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_004.png" alt="1 Intro to Bayesian Inference" class = "sphx-glr-single-img"/><div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">PlotPosterior</span><span class="p">(</span><span class="n">az_data</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">create_figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">joyplot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">marginal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">plot_marginal</span><span class="p">(</span><span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">],</span>
                <span class="n">plot_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">credible_interval</span><span class="o">=</span><span class="mf">.93</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;kde&#39;</span><span class="p">,</span>
                <span class="n">joint_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;contour&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;pcolormesh_kwargs&#39;</span><span class="p">:</span> <span class="p">{}},</span>
                <span class="n">joint_kwargs_prior</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;contour&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;pcolormesh_kwargs&#39;</span><span class="p">:</span> <span class="p">{}})</span>

<span class="n">p</span><span class="o">.</span><span class="n">plot_normal_likelihood</span><span class="p">(</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">,</span> <span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">hide_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">1.70</span><span class="p">,</span> <span class="mf">2.40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_005.png" srcset="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_005.png" alt="Likelihood" class = "sphx-glr-single-img"/><div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">az_data</span> <span class="o">=</span> <span class="n">infer_model</span><span class="p">(</span><span class="s2">&quot;u_o&quot;</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Warmup:   0%|          | 0/200 [00:00, ?it/s]
Warmup:  10%|#         | 20/200 [00:00, 195.28it/s, step size=1.48e-01, acc. prob=0.741]
Warmup:  20%|##        | 40/200 [00:00, 180.71it/s, step size=1.06e-01, acc. prob=0.762]
Warmup:  32%|###1      | 63/200 [00:00, 201.43it/s, step size=2.28e-01, acc. prob=0.777]
Warmup:  42%|####2     | 84/200 [00:00, 194.68it/s, step size=2.43e-01, acc. prob=0.782]
Sample:  53%|#####3    | 106/200 [00:00, 202.44it/s, step size=3.54e-01, acc. prob=0.865]
Sample:  64%|######3   | 127/200 [00:00, 198.27it/s, step size=3.54e-01, acc. prob=0.955]
Sample:  74%|#######4  | 149/200 [00:00, 202.88it/s, step size=3.54e-01, acc. prob=0.950]
Sample:  86%|########6 | 172/200 [00:00, 211.06it/s, step size=3.54e-01, acc. prob=0.927]
Sample:  97%|#########7| 194/200 [00:00, 199.42it/s, step size=3.54e-01, acc. prob=0.941]
Sample: 100%|##########| 200/200 [00:00, 200.10it/s, step size=3.54e-01, acc. prob=0.943]

/home/leguark/.virtualenvs/gempy-geotop-pilot/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: gempy.-version- is an invalid version and will not be supported in a future release
  warnings.warn(
</pre></div>
</div>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">PlotPosterior</span><span class="p">(</span><span class="n">az_data</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">create_figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">joyplot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">marginal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">plot_marginal</span><span class="p">(</span><span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">],</span>
                <span class="n">plot_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">credible_interval</span><span class="o">=</span><span class="mf">.93</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;kde&#39;</span><span class="p">,</span>
                <span class="n">joint_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;contour&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;pcolormesh_kwargs&#39;</span><span class="p">:</span> <span class="p">{}},</span>
                <span class="n">joint_kwargs_prior</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;contour&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;pcolormesh_kwargs&#39;</span><span class="p">:</span> <span class="p">{}})</span>

<span class="n">p</span><span class="o">.</span><span class="n">axjoin</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">1.96</span><span class="p">,</span> <span class="mf">2.22</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">plot_normal_likelihood</span><span class="p">(</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">,</span> <span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=-</span><span class="mi">6</span><span class="p">,</span> <span class="n">hide_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">1.70</span><span class="p">,</span> <span class="mf">2.40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_006.png" srcset="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_006.png" alt="Likelihood" class = "sphx-glr-single-img"/><div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">az_data</span> <span class="o">=</span> <span class="n">infer_model</span><span class="p">(</span><span class="s2">&quot;u_s&quot;</span><span class="p">,</span> <span class="n">y_obs_list</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">PlotPosterior</span><span class="p">(</span><span class="n">az_data</span><span class="p">)</span>

<span class="n">p</span><span class="o">.</span><span class="n">create_figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">joyplot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">marginal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">plot_marginal</span><span class="p">(</span><span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">],</span>
                <span class="n">plot_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">credible_interval</span><span class="o">=</span><span class="mf">.93</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;kde&#39;</span><span class="p">,</span>
                <span class="n">joint_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;contour&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;pcolormesh_kwargs&#39;</span><span class="p">:</span> <span class="p">{}},</span>
                <span class="n">joint_kwargs_prior</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;contour&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;pcolormesh_kwargs&#39;</span><span class="p">:</span> <span class="p">{}})</span>

<span class="n">p</span><span class="o">.</span><span class="n">plot_normal_likelihood</span><span class="p">(</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\sigma$&#39;</span><span class="p">,</span> <span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=-</span><span class="mi">5</span><span class="p">,</span> <span class="n">hide_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">axjoin</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">1.96</span><span class="p">,</span> <span class="mf">2.22</span><span class="p">)</span>
<span class="n">p</span><span class="o">.</span><span class="n">likelihood_axes</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">1.70</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_007.png" srcset="../../_images/sphx_glr_1_Intro_to_Bayesian_Inference_007.png" alt="Likelihood" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Warmup:   0%|          | 0/200 [00:00, ?it/s]
Warmup:  14%|#3        | 27/200 [00:00, 266.07it/s, step size=9.15e-02, acc. prob=0.775]
Warmup:  27%|##7       | 54/200 [00:00, 177.01it/s, step size=1.21e-02, acc. prob=0.768]
Warmup:  37%|###7      | 74/200 [00:00, 161.17it/s, step size=3.31e-02, acc. prob=0.781]
Warmup:  46%|####5     | 91/200 [00:00, 146.92it/s, step size=2.59e-01, acc. prob=0.762]
Sample:  60%|######    | 121/200 [00:00, 189.29it/s, step size=2.42e-01, acc. prob=0.971]
Sample:  76%|#######6  | 153/200 [00:00, 225.50it/s, step size=2.42e-01, acc. prob=0.965]
Sample:  94%|#########3| 187/200 [00:00, 257.51it/s, step size=2.42e-01, acc. prob=0.951]
Sample: 100%|##########| 200/200 [00:00, 218.30it/s, step size=2.42e-01, acc. prob=0.954]

/home/leguark/.virtualenvs/gempy-geotop-pilot/lib/python3.10/site-packages/arviz/data/io_pyro.py:157: UserWarning: Could not get vectorized trace, log_likelihood group will be omitted. Check your model vectorization or set log_likelihood=False
  warnings.warn(
</pre></div>
</div>
</section>
<section id="license">
<h1>License<a class="headerlink" href="#license" title="Permalink to this heading">¶</a></h1>
<p>The code in this case study is copyrighted by Miguel de la Varga and licensed under the new BSD (3-clause) license:</p>
<p><a class="reference external" href="https://opensource.org/licenses/BSD-3-Clause">https://opensource.org/licenses/BSD-3-Clause</a></p>
<p>The text and figures in this case study are copyrighted by Miguel de la Varga and licensed under the CC BY-NC 4.0 license:</p>
<p><a class="reference external" href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</a>
Make sure to replace the links with actual hyperlinks if you’re using a platform that supports it (e.g., Markdown or HTML). Otherwise, the plain URLs work fine for plain text.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  13.444 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-first-example-of-inference-1-bayesian-basics-1-intro-to-bayesian-inference-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/3571d5487c4365399443b0f61ad79d17/1_Intro_to_Bayesian_Inference.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">1_Intro_to_Bayesian_Inference.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/af9c46b0a536742e474429ea7d1f5197/1_Intro_to_Bayesian_Inference.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">1_Intro_to_Bayesian_Inference.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/logos/gempy.png" alt="Logo"/>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gempy-project&repo=gempy&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Probabilistic modeling for Structural Geology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples_intro/index.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">﻿1 - First example of inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples_basic_geology/index.html">﻿2 - Probabilistic Geomodel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples_probabilistic_inversion/index.html">﻿3 - Probabilistic Geophysics (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples_utils/index.html">﻿Utilities</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference.html">Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference.html#data-classes">Data Classes</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023-2023, Gempy Probability Developers.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../../_sources/examples_first_example_of_inference/1-bayesian_basics/1_Intro_to_Bayesian_Inference.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>